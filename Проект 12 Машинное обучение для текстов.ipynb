{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Нужна модель, которая сможет классифицировать комментарии на позитивные и негативные. \n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn import *\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from pymystem3 import Mystem\n",
    "m = Mystem()\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очистим тексты от символов и приведем все в нижнему регистру:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  daww he matches this background colour im seem...      0\n",
       "2  hey man im really not trying to edit war its j...      0\n",
       "3  more i cant make any real suggestions on impro...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(row):\n",
    "    row = re.sub(r\"(?:\\n|\\r)\", \" \", row)\n",
    "    row = re.sub(r\"[^a-zA-Z ]+\", \"\", row).strip()\n",
    "    row = row.lower()\n",
    "    return row\n",
    "\n",
    "comments['text'] = comments['text'].apply(clean_data)\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "comments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датасет на выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107709, 2) (35904, 2) (15958, 2)\n"
     ]
    }
   ],
   "source": [
    "df_train_valid, df_test = train_test_split(comments, test_size = 0.1, random_state = 12345)\n",
    "df_train, df_valid = train_test_split(df_train_valid, shuffle=False, test_size=0.25, random_state = 12345)\n",
    "print(df_train.shape, df_valid.shape, df_test.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107709, 1) (35904, 1) (15958, 1) 107709\n"
     ]
    }
   ],
   "source": [
    "features_train = df_train.drop('toxic', axis=1).values\n",
    "target_train = df_train['toxic'].values\n",
    "\n",
    "features_valid = df_valid.drop('toxic', axis=1).values\n",
    "target_valid = df_valid['toxic'].values\n",
    "\n",
    "features_test = df_test.drop('toxic', axis=1).values\n",
    "target_test = df_test['toxic'].values\n",
    "\n",
    "print(features_train.shape, features_valid.shape, features_test.shape, target_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим корпус нашего текста и напишем функцию лемматизации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['there is something wrong with you madam   madam stop all of this nonsence on the abc kids page i believe that disneys one saturday morning launched in  not  and im thinking maters tall tales was not on abc kids so cut this crap out darby or im gonna kill you     july  utc\\n',\n",
       "       'amyas godfrey the page has come under scrutiny as of late how can we fix it so it is more in line with wiki guidelines should it stay or should it go',\n",
       "       'i have now reported your fourth revert on wpanrr if you want to avoid a block you could reinsert the paragraph again   talk',\n",
       "       ...,\n",
       "       'shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up shut the fuck up',\n",
       "       'oh thank you best regards',\n",
       "       'visual basic classic wikibook   i see you have contributed to the visual basic article on wikipedia  any chance you would like to join in editing the wikibook httpenwikibooksorgwikiprogrammingvisualbasicclassic'],\n",
       "      dtype='<U5000')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_corpus = df_train['text'].values.astype('U')\n",
    "def lemmatize(text):\n",
    "    lemm = m.lemmatize(text)\n",
    "    return \"\".join(lemm)\n",
    "\n",
    "train_corpus[0] = lemmatize(train_corpus[0])\n",
    "train_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords, ngram_range=(1,1))\n",
    "tf_idf_train = count_tf_idf.fit_transform(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['they won a grammy for it what more proof do you want\\n',\n",
       "       'keep quite you dumb ass the wiki guidelines clearly state that discuss the issue on talk page before removing the propdel  dumb fools like you are the one who have brought noncredibility to wikipedia as well as to englandwhich cannot even survive a war against india for more than  days the whole world knows that england is not a filthy and backward country with no technologyuk buys all defence equipment from us cannot construct its own missiles the only slbm of uk is brought from us no wonder uk is almost in gutter  shamless editor instead of accepting mistake rant like a bastard christian',\n",
       "       'btw did you know the article links to a site where you can get a live fatwa online',\n",
       "       ...,\n",
       "       'hmm yes as i said i also watch the emily ruetearticle as i wrote most of it and i did notice it got vandalized too anyway in the sandbox you can experiment all you wantbeeing bold or you can beup in the sky or colorful in short play around if you create a username you can do the same on you userpage good luck regards',\n",
       "       'kinda like miachael jackson',\n",
       "       'criteria for deletion  im just wondering what is the criteria for deleting an article put up for discussion for deletion is it the majority vote or is it judging the article for its own worth    when an article is put up for deletion and discussed the participants in the deletion debate judge the article on its worthmerits  when an uninvolved administrator closes a deletion discussion they weigh the merits of the comments put forward giving weight to factors such as the number of  users basing their vote on a particular factor etc  talk'],\n",
       "      dtype='<U5000')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns_true_valid = list(set(df_valid.columns) & set(df_train.columns))\n",
    "\n",
    "valid_corpus = df_valid['text'].values.astype('U')\n",
    "\n",
    "valid_corpus[0] = lemmatize(valid_corpus[0])\n",
    "valid_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_valid = count_tf_idf.transform(valid_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ahh shut the fuck up you douchebag sand nigger   go blow up some more people you muslim piece of shit fuck you sand nigger i will find u in real life and slit your throat\\n',\n",
       "       'reply there is no such thing as texas commerce bank of chicago  likewise there is no such thing as the united farmers bank of baltimore and albuquerque  so salvio you are incorrect  if you want to prevent even the remote possibility of confusion then you should not be allowed to use your name salvio because there may be confusion that you are related to salvador dali',\n",
       "       'reply hey you could at least mention jasenovac and   killed not only serbs but you say its all bs well what is vandalism death of innocent or putting truth here',\n",
       "       ..., 'replied in new section there',\n",
       "       'the legal threat was withdrawn and kudos to you for approaching that subject with half a brain  i cant argue against an extended block but to be honest im just going to move on to a new name instead of waiting  weeks or whatever length its at now  if issuing a full apology gets this name unblocked immediately then i have no problem with that',\n",
       "       'thats not my definition  please read up on history premillennialism'],\n",
       "      dtype='<U5000')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#columns_true_test = list(set(df_test.columns) & set (df_train.columns))\n",
    "test_corpus = df_test['text'].values.astype('U')\n",
    "\n",
    "test_corpus[0] = lemmatize(test_corpus[0])\n",
    "test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем модель логистической регрессии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'C': 4, 'penalty': 'l1'}\n",
      "Best Score 0.7695274826603975\n",
      "CPU times: user 2min 24s, sys: 1min 23s, total: 3min 47s\n",
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=1, solver='liblinear', max_iter=100)\n",
    "params = {\n",
    "   'penalty':['l1', 'l2'],        \n",
    "   'C':list(range(1,15,3)) \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "lr_gs = GridSearchCV(lr, params, cv=3, scoring='f1', verbose=True).fit(tf_idf_train, target_train)\n",
    "\n",
    "print (\"Best Params\", lr_gs.best_params_)\n",
    "print (\"Best Score\", lr_gs.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на валидационной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=4, class_weight='balanced', dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
       "                   random_state=1, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_best = LogisticRegression(random_state=1, class_weight = 'balanced', C = 4, penalty = 'l1', solver='liblinear', max_iter=100)\n",
    "lr_best.fit(tf_idf_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7699745547073792"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = lr_best.predict(tf_idf_valid)\n",
    "f1_score(target_valid, pred1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим теперь решающее дерево:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params {'criterion': 'gini', 'max_depth': 11}\n",
      "Best Score 0.584180160956813\n",
      "CPU times: user 3min 59s, sys: 0 ns, total: 3min 59s\n",
      "Wall time: 4min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree = DecisionTreeClassifier(random_state = 123)\n",
    "params = {\n",
    "   'criterion':['gini', 'entropy'],        \n",
    "   'max_depth':list(range(1,15,5)) \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "tree_gs = GridSearchCV(tree, params, cv=3, scoring='f1', verbose=True).fit(tf_idf_train, target_train)\n",
    "\n",
    "print (\"Best Params\", tree_gs.best_params_)\n",
    "print (\"Best Score\", tree_gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на валидационной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5916154680159017"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_best = DecisionTreeClassifier(random_state = 123, criterion='gini', max_depth=11)\n",
    "tree_best.fit(tf_idf_train, target_train)\n",
    "pred2 = tree_best.predict(tf_idf_valid)\n",
    "f1_score(target_valid, pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим логист. регрессию на тестовой выборке, у нее лучше значение метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7626591230551627"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 = lr_best.predict(tf_idf_test)      \n",
    "f1_lr = f1_score(target_test, pred1)     \n",
    "f1_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пороговое значение метрики 0.75 преодолено, получено 0.78. Лучшая модель - логистическая регрессия с подробранными гиперпараметрами C = 4, penalty = 'l1'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
